---
title: "Longitudinal Data Analysis Assignment 2"
author: "Andomei Smit: SMTAND051"
date: "01/09/2025"
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 2
    fig_caption: true
    keep_tex: true
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = 'H')
library(nlme)
library(faraway)
library(lattice)
library(dplyr)
library(ggplot2)
library(tidyr)
library(MuMIn)
```

# Introduction

```{r}
# read in the data
malaria <- read.csv("malariadata.csv")
#head(malaria)

# random sample carefully so that records stay complete
set.seed(1997)
# sample 75% of unique pids
sampled_pids <- malaria %>%
  distinct(pid) %>%
  slice_sample(prop = 0.75) %>%
  pull(pid)

# keep all rows for those pids
malaria <- malaria %>% semi_join(tibble(pid = sampled_pids), by = "pid")

# order malaria by pid
malaria <- malaria[order(malaria$pid, malaria$pday),]
rm(sampled_pids)
```

# Data Cleaning

```{r}
unique(malaria$Studyyear) # all 2003, can drop it!
unique(malaria$country) # all Mozambique, so can drop it!

# remove Studyyear, country, Hb, pardens, gamedens, PIoutcome, PIoutcomeday and Sulfconcentration
malaria <- malaria %>% select(-c(Studyyear, country, Hb, pardens, gamedens, PIoutcome, PIoutcomeday, Sulfconcentration))

# what columns are left
colnames(malaria)

# how many subjects per site?
malaria %>%
  distinct(pid, site) %>%     # ensure one row per subject–site
  count(site, name = "n_subjects")

# collapse the sites to north and south regions
malaria <- malaria %>%
  mutate(region = case_when(
    site %in% c("Namaacha","Catuane","Boane") ~ "South",
    site == "Magude" ~ "North",
    TRUE ~ as.character(site)   # fallback in case of other sites
  ))
# drop site
malaria <- malaria %>% select(-site)

# missing values in responses: 
colSums(is.na(malaria))

# create new dataframe for Pyr with no NA:
pyr_df  <- subset(malaria, !is.na(Pyrconcentration))

# remove patients who have an increase in drug concentration after day 3
pyr_bad_ids <- pyr_df %>%
  filter(pday > 3) %>%
  group_by(pid) %>%
  arrange(pday) %>%
  summarise(any_increase = any(diff(Pyrconcentration) > 0, na.rm = TRUE)) %>%
  filter(any_increase) %>%
  pull(pid)

# Drop those patients
pyr_df <- pyr_df %>%
  filter(!pid %in% pyr_bad_ids)

# create correct data types, center and scale covariates
pyr_df$pid    <- factor(pyr_df$pid)
pyr_df$arm    <- factor(pyr_df$arm) 
pyr_df$gender <- factor(pyr_df$gender)
pyr_df$region <- factor(pyr_df$region)
pyr_df$pday   <- as.numeric(pyr_df$pday)

# center/scale continuous covariates (optional but helpful)
pyr_df$c_weight <- scale(pyr_df$weight, center=TRUE, scale=FALSE)
pyr_df$c_age    <- scale(pyr_df$age,    center=TRUE, scale=FALSE)
```

# EDA

## Correlation checks

```{r}
# correlation between age and weight
cor(pyr_df$age, pyr_df$weight, use="complete.obs") # very high
```

## Specific questions

```{r}
# number of patients within pyr
length(unique(pyr_df$pid)) # 245
length(unique(malaria$pid)) # 306
```

```{r}
# are age and weight constant within patient?
df_age_weight <- malaria %>%
  group_by(pid) %>%
  summarise(
    n_age = n_distinct(age),
    n_weight = n_distinct(weight)
  ) %>%
  # filter for only records where either age or weight has > 1 distinct values
  filter(n_age > 1 | n_weight > 1)
# empty data frame, thus age and weight are constant within patient
rm(df_age_weight)
```

## Distribution of continuous covariates between regions and arm

```{r}
# begin by summarising the data at pid level
# Subject-level reductions
subjects <- malaria %>%
  arrange(pid, pday) %>%
  group_by(pid) %>%
  summarise(
    arm     = dplyr::first(na.omit(arm)),
    region  = dplyr::first(na.omit(region)),
    gender  = dplyr::first(na.omit(gender)),
    age     = dplyr::first(na.omit(age)),  
    weight  = dplyr::first(na.omit(weight)),
    .groups = "drop"
  )
```

```{r}
# summarise age by region and arm
var_to_plot <- "age"

# Boxplots/violin by arm within each region
p_age <- ggplot(subjects, aes(x = arm, y = .data[[var_to_plot]], fill = arm)) +
  geom_violin(trim = FALSE, alpha = 0.25, na.rm = TRUE, color = NA) +
  geom_boxplot(width = 0.2, outlier.shape = 21, na.rm = TRUE) +
  facet_wrap(~ region, scales = "fixed") +
  labs(x = "Arm", y = var_to_plot, title = paste("Distribution of", var_to_plot, "by Arm within Region")) +
  theme_bw() + theme(legend.position = "none")

ggsave("plots/age_dbn.pdf", plot = p_age, width = 5, height = 3)
```

```{r}
var_to_plot <- "weight"

# Boxplots/violin by arm within each region
p_weight <- ggplot(subjects, aes(x = arm, y = .data[[var_to_plot]], fill = arm)) +
  geom_violin(trim = FALSE, alpha = 0.25, na.rm = TRUE, color = NA) +
  geom_boxplot(width = 0.2, outlier.shape = 21, na.rm = TRUE) +
  facet_wrap(~ region, scales = "fixed") +
  labs(x = "Arm", y = var_to_plot, title = paste("Distribution of", var_to_plot, "by Arm within Region")) +
  theme_bw() + theme(legend.position = "none")

ggsave("plots/weight_dbn.pdf", plot = p_weight, width = 5, height = 3)
```

## Dropout rate: pyr

```{r}
# time on study/ dropout pattern
last_obs_pyr <- malaria %>%
  filter(!is.na(Pyrconcentration)) %>%                 # only rows where Pyr is observed
  group_by(pid) %>%
  summarise(
    last_pday = max(pday),               # last day observed for that pid
    n_obs     = n(),                     # how many Pyr measurements they have
    .groups = "drop"
  )

subjects <- malaria %>% distinct(pid, arm, region)

# counts of last observed day by arm
last_by_arm_pyr <- last_obs_pyr %>%
  left_join(subjects, by = "pid") %>%
  count(arm, last_pday, name = "n_subjects") %>%
  tidyr::pivot_wider(names_from = arm, values_from = n_subjects, values_fill = 0)

unique_days <- sort(unique(malaria$pday))

retention <- dplyr::bind_rows(lapply(unique_days, function(d) {
  last_obs_pyr %>%
    left_join(subjects, by = "pid") %>%
    group_by(arm) %>%
    summarise(n_at_least_d = sum(!is.na(last_pday) & last_pday >= d), .groups = "drop") %>%
    mutate(pday = d)
}))


p_ret_pyr <- ggplot(retention, aes(x = pday, y = n_at_least_d, color = arm)) +
   geom_line(linewidth = 1) + 
  geom_point() +
   labs(y = "Subjects with observed ≥ day", title = "Retention over time by Arm (Pyrimethamine)")+
  theme_bw()
ggsave("plots/retention_arm_pyr.pdf", plot = p_ret_pyr, height = 3, width = 5)
```


```{r}
# retention by region
last_obs <- malaria %>%
  filter(!is.na(Pyrconcentration)) %>%
  group_by(pid) %>%
  summarise(last_pday = max(pday), .groups = "drop")

# attach region info
subjects <- malaria %>% distinct(pid, region)
last_obs <- left_join(last_obs, subjects, by = "pid")

unique_days <- sort(unique(malaria$pday))

retention_region <- bind_rows(lapply(unique_days, function(d) {
  last_obs %>%
    group_by(region) %>%
    summarise(
      n_at_least_d = sum(!is.na(last_pday) & last_pday >= d),
      .groups = "drop"
    ) %>%
    mutate(pday = d)
}))

p_ret_reg <- ggplot(retention_region, aes(x = pday, y = n_at_least_d, color = region)) +
  geom_line(linewidth = 1) +
  geom_point() +
  labs(
    x = "Day",
    y = "Subjects with observed ≥ day",
    title = "Retention over time by Region (Pyrimethamine)"
  ) +
  theme_bw()
ggsave("plots/retention_region_pyr.pdf", plot = p_ret_reg, width = 5, height = 3)
```

## Pyr dataset questions

```{r}
# gender: are the males and females balanced?
pyr_df %>%
  distinct(pid, gender) %>%   
  filter(gender == "F") %>%
  summarise(n_females = n())
# 156 of 245, roughly 64%
```

```{r}
# arm: are the treatments balanced?
pyr_df %>%
  distinct(pid, arm) %>%   
  filter(arm == "SP") %>%
  summarise(n_SP = n())
# 119 out of 245 is SP, thus roughly balanced according to treatment
```

```{r}
# do both regions offer both treatments?
pyr_df %>%
  group_by(region, arm) %>%
  summarise(n_unique_pid = n_distinct(pid), .groups = "drop")
# roughly balanced between regions
```

## Subject profiles

```{r}
## plot scatterplot of drug concentrations:
pyr_df$arm <- as.factor(pyr_df$arm)

#pdf("plots/scatter_drug_time.pdf", height = 4, width = 7)
#op <- par(mfrow = c(1,2))
#with(pyr_df,  plot(pday, Pyrconcentration,  pch = 16, cex = .6, col = as.integer(arm),
#                   main = "Pyrimethamine (raw)", xlab = "Day", ylab = #"Concentration"))
#legend("topright", legend = levels(pyr_df$arm), pch = 16, col = #seq_along(levels(pyr_df$arm)), bty = "n")

#with(sulf_df, plot(pday, Sulfconcentration, pch = 16, cex = .6, col = as.integer(arm),
#                   main = "Sulfadoxine (raw)", xlab = "Day", ylab = "Concentration"))
#legend("topright", legend = levels(sulf_df$arm), pch = 16, col = seq_along(levels(sulf_df$arm)), bty = "n")
#par(op)
#dev.off()

## plot spaghetti plots of drug concentrations:
# Pyrimethamine
g_pyr <- ggplot(pyr_df, aes(pday, Pyrconcentration, group = pid, colour = arm)) +
  geom_line(alpha = 0.25, linewidth = 0.4) +
  facet_wrap(~ arm, nrow = 1) +
  labs(title = "Pyrimethamine concentration",
       x = "Day", y = "Concentration") +
  theme_minimal() + 
  theme(legend.position = "none")
ggsave("plots/pyr_time.pdf", plot = g_pyr, width = 6, height = 3)
```

```{r}
rm(g_pyr)
rm(last_by_arm_pyr)
rm(last_obs)
rm(last_obs_pyr)
rm(p_age)
rm(p_ret_pyr)
rm(p_ret_reg)
rm(p_weight)
rm(retention)
rm(retention_region)
rm(subjects)
rm(pyr_df)
rm(df)
rm(pyr_bad_ids)
rm(unique_days)
rm(var_to_plot)
```

# Model fitting: Pyr

## Fit individual models

```{r}
#  since we don't have a dose, we can just make the dose the same for everyone
pyr_df$Dose_Pyr <- 1 
# drop the all rows with NA in weight column:
pyr_df_cc <- subset(as.data.frame(pyr_df), !is.na(weight))

pyr_gd <- groupedData(Pyrconcentration ~ pday | pid, data = pyr_df_cc)

pyr_nls <- nlsList(
  Pyrconcentration ~ SSfol(Dose_Pyr, pday, lKe, lKa, lCl),
  data     = pyr_gd,
  na.action = na.omit,
  control  = nls.control(maxiter = 100, warnOnly = TRUE)
)

pairs(pyr_nls, id = 0.1) # idea of the correlation between individual parameter estimates
# appears to have very strong correlations between the parameter estimates
```


```{r}
# plot the confidence intervals of the estimates
out <- summary(pyr_nls)

cf_wide <- as.data.frame(out$coefficients)
# drop all NA:
cf_wide_noNA <- cf_wide[complete.cases(cf_wide), ]
pid <- rownames(cf_wide_noNA)

# Helper to build a tidy df and plot for one parameter
plot_param_ci <- function(df, est_col, se_col, title) {
  d <- tibble(
    pid    = rownames(df),
    est    = df[[est_col]],
    se     = df[[se_col]]
  ) %>%
    mutate(
      lower = est - 1.96 * se,
      upper = est + 1.96 * se,
      width = upper - lower
    ) %>%
    arrange(desc(width))     # sort from widest to narrowest
  
  # Drop the top 20 widest
  if (nrow(d) > 20) {
    d <- d[-(1:20), ]
  }
  
  ggplot(d, aes(x = reorder(pid, est), y = est, ymin = lower, ymax = upper)) +
    geom_pointrange() +
    coord_flip() +
    theme_bw() +
    labs(x = "Subject (pid)", y = "Estimate ± 95% CI", title = title)
}


# 1) lKe
p_lKe <- plot_param_ci(cf_wide_noNA, "Estimate.lKe", "Std. Error.lKe", "lKe: per-subject estimates with 95% CI")
p_lKe
ggsave("plots/ci_plot_lke.pdf", plot = p_lKe, width = 5, height = 3)

# 2) lKa
p_lKa <- plot_param_ci(cf_wide_noNA, "Estimate.lKa", "Std. Error.lKa", "lKa: per-subject estimates with 95% CI")
p_lKa
ggsave("plots/ci_plot_lka.pdf", plot = p_lKa, width = 5, height = 3)

# 3) lCl
p_lCl <- plot_param_ci(cf_wide_noNA, "Estimate.lCl", "Std. Error.lCl", "lCl: per-subject estimates with 95% CI")
p_lCl
ggsave("plots/ci_plot_lcl.pdf", plot = p_lCl, width = 5, height = 3)
```

## Fit a basic nlme model

Now fit an nlme. Note that we use pdDiag, which specifies that the random effects are indepentent (i.e. the variance-covariance matrix is diagonal).

```{r}
pyr_nlme_base <- nlme(pyr_nls,                       
  random  = pdDiag(lKe + lKa ~ 1),
  method  = "REML"
)

# note the following causes convergence issues 
#try <- nlme(pyr_nls,
     #       random = lKe + lKa ~1,
      #      method = "REML")

# running lKa, lCl and lKe did not converge
# removing lKa lead to singularities
# removing lCl lead to immediate convergence
# removing lKe still did not converge

m0_REML <- pyr_nlme_base

summary(m0_REML) # these look ok, but note high correlations between parameters
# also note the very small standard deviation for lKa, indicating it could be removed
VarCorr(m0_REML) # some are almost zero

## residual diagnostics
pdf("plots/resid_vs_fitted_base.pdf", width = 4, height = 4)
#par(mfrow = c(1,2))
plot(m0_REML)   # residuals vs fitted by id
dev.off()
pdf("plots/qq_base.pdf", width = 4, height = 4)
qqnorm(resid(m0_REML))  # residual normality, no clear fan shape
qqline(resid(m0_REML))
#plot(augPred(m0_REML), layout = c(4,4), pages = 1)  # quick VPC 
dev.off()
#par(mfrow = c(1,1))
```

We're going to make 2 changes:
1. Switch to ML to be able to run likelihood ratio tests
2. Remove lKa from the random effects due to tiny variance estimation (meaning it may be too complex for ML to evaluate with that included)

```{r}
m1_ML <- update(
  pyr_nlme_base,
  method = "ML",
  random = lKe ~ 1   # drop lKa RE; keep lKe RE only
)
summary(m1_ML)
VarCorr(m1_ML) # the large residuals is apparently typical for PK data
```

## Adding covariates

We will do some EDA to determine which covariates to test.

- Currently the fixed effects are: fixed = lKe + lKa + lCl ~ 1.

### EDA
Residuals vs fitted 

```{r}
plot(m1_ML, cex = 0.8, adj =-0.5)

# residual QQ plot
qqnorm(resid(m1_ML, type = "normalized")); qqline(resid(m1_ML, type = "normalized"))
## large deviations at tails
```

```{r}
# qqplot of random effects
qqnorm(m1_ML, ~ ranef(.)) # seems to be normal
```

Now plot the random effect against each covariate.

```{r}
## 1) Subject-level BLUP + covariates -------------------------------
re    <- ranef(m1_ML) %>% as.data.frame()      # or m1_ML
re_df <- tibble::rownames_to_column(re, "pid")

dat0  <- getData(m1_ML) %>% as.data.frame()

dat_re <- dat0 %>% left_join(re_df, by = "pid")

# If your ranef column isn't named 'lKe', change it below
subj <- dat_re %>%
  group_by(pid) %>%
  summarise(
    b_lKe    = first(na.omit(lKe)),   # BLUP (random effect) for lKe
    c_weight = first(na.omit(c_weight)),
    c_age    = first(na.omit(c_age)),
    gender   = first(na.omit(gender)),
    arm      = first(na.omit(arm)),
    region   = first(na.omit(region)),
    .groups  = "drop"
  )

## 2) Continuous: BLUP vs c_weight / c_age --------------------------
cont_long <- subj %>%
  select(pid, b_lKe, c_weight, c_age) %>%
  pivot_longer(cols = c(c_weight, c_age), names_to = "covar", values_to = "x") %>%
  filter(!is.na(x), !is.na(b_lKe))

p_cont <- ggplot(cont_long, aes(x = x, y = b_lKe)) +
  geom_point(alpha = 0.7) +
  geom_smooth(se = FALSE) +
  facet_wrap(~ covar, scales = "free_x") +
  theme_bw() +
  labs(title = "BLUP(lKe) vs continuous covariates",
       x = "Covariate value", y = "BLUP: lKe")
p_cont

## 3) Categorical: BLUP by gender / arm / region --------------------
ggplot(filter(subj, !is.na(gender)),
    aes(x = as.factor(gender), y = b_lKe)) +
  geom_boxplot(outlier.alpha = 0.5) +
  theme_bw() +
  labs(title = "BLUP(lKe) by gender", x = "gender", y = "BLUP: lKe")

ggplot(filter(subj, !is.na(arm)),
    aes(x = as.factor(arm), y = b_lKe)) +
  geom_boxplot(outlier.alpha = 0.5) +
  theme_bw() +
  labs(title = "BLUP(lKe) by arm", x = "arm", y = "BLUP: lKe")

ggplot(filter(subj, !is.na(region)),
        aes(x = as.factor(region), y = b_lKe)) +
  geom_boxplot(outlier.alpha = 0.5) +
  theme_bw() +
  labs(title = "BLUP(lKe) by region", x = "region", y = "BLUP: lKe")
```

### Adding age and weight

The only noticible interesting trends are for age and weight. So we will try to add these.

- We can add weight as a fixed effect on lKe (our only random effect). Recall in this case that we are estimating the following parameters: lKe, lKa and lCl. We now want to specify how the covariates influence these parameters. So we do it as below to essentially say there is a population mean for lKe (~1, plus a slope on the weight)

```{r}
# Use centered weight
# Intercepts from the converged base ML model (order: lKe, lKa, lCl)
# get current fixed-effect starts (order: lKe, lKa, lCl)
beta0 <- unname(fixef(m1_ML))

# add linear + quadratic weight on lKe
m2w_ML <- update(
  m1_ML,
  fixed = list(
    lKe ~ 1 + c_weight + I(c_weight^2),
    lKa ~ 1,
    lCl ~ 1
  ),
  # starts: lKe_intercept, lKe_c_weight, lKe_c_weight^2, lKa_intercept, lCl_intercept
  start = c(beta0[1], 0, 0, beta0[2], beta0[3])
)

# compare
anova(m1_ML, m2w_ML) # highly significant
summary(m2w_ML)
```
Now let's do age:

```{r}
# Add linear + quadratic age on lKe
m2a_ML <- update(
  m1_ML,
  fixed = list(
    lKe ~ 1 + c_age + I(c_age^2),
    lKa ~ 1,
    lCl ~ 1
  ),
  # start vector: lKe_intercept, lKe:c_age, lKe:c_age^2, lKa_intercept, lCl_intercept
  start = c(beta0[1], 0, 0, beta0[2], beta0[3])
)

# Likelihood ratio test vs base
anova(m1_ML, m2a_ML) # also significant
summary(m2a_ML)
```

Now let's combine both into the same model.

```{r}
beta0 <- unname(fixef(m1_ML))

m3_ML <- update(
  m1_ML,
  fixed = list(
    lKe ~ 1 + c_weight + I(c_weight^2) + c_age + I(c_age^2),
    lKa ~ 1,
    lCl ~ 1
  ),
  # intercept, weight slope, weight^2, age slope, age^2, lKa intercept, lCl intercept
  start = c(beta0[1], 0, 0, 0, 0, beta0[2], beta0[3])
)

anova(m1_ML, m3_ML)   # very significant.
summary(m3_ML) # which are individually significant:
## only I(c_age^2) does not seem significant

VarCorr(m3_ML) # variance of lKe got smaller since we explained part of it.
VarCorr(m1_ML)
```
Let's drop age^2:

```{r}
m4_ML <- update(
  m1_ML,
  fixed = list(
    lKe ~ 1 + c_weight + I(c_weight^2) + c_age,
    lKa ~ 1,
    lCl ~ 1
  ),
  # start vector: intercept, weight slope, weight^2, age slope, lKa intercept, lCl intercept
  start = c(beta0[1], 0, 0, 0, beta0[2], beta0[3])
)

anova(m1_ML, m4_ML)   # compare vs base: highly significant
anova(m3_ML, m4_ML)   # adding age^2 doesn't improve fit
summary(m4_ML) # all are sigificant now
VarCorr(m4_ML) # variance still shrunk for lKe
```

Now refit with REML.

```{r}
m_final <- update(m4_ML, method = "REML")
summary(m_final)
VarCorr(m_final) # no negative variances, residual var increased, but variance of lKe decreased
VarCorr(m1_ML)
```
Let's check diagnostics again:
```{r}
res <- resid(m_final, type = "normalized")  

# Residual plots
par(mfrow = c(1,2))
plot(m_final)  # residuals vs fitted
qqnorm(res, main = "QQ plot of residuals")
qqline(res, col = "red", lwd = 2) 
par(mfrow = c(1,1))

hist(res, breaks = 20, prob = TRUE,
     main = "Histogram of residuals", xlab = "Residuals")
lines(density(res), col = "blue", lwd = 2)

# Random effects (BLUPs) vs covariates
re <- ranef(m_final)
qqnorm(re[,1], main = "QQ plot of random effect (lKe)")
qqline(re, col = "red", lwd = 2)
hist(re[,1], breaks = 15, prob = TRUE,
     main = "Histogram of random effect (lKe)", xlab = "lKe")
lines(density(re[,1]), col = "blue", lwd = 2)
```


## Check variance structure

Do the residuals differ by arm, gender or region?
```{r}
## 1) Residuals and their subject IDs (exactly matches model rows)
res <- resid(m4_ML, type = "normalized")                 # length = nobs(model)
pid <- as.character(getGroups(m4_ML, level = 1))         # same length as res

df_used <- data.frame(pid = pid, res = as.numeric(res))  # one row per used observation

## 2) Subject-level covariates (take first non-missing per pid)
covs <- as.data.frame(pyr_gd) %>%
  group_by(pid) %>%
  summarise(
    arm    = first(na.omit(arm)),
    region = first(na.omit(region)),
    gender = first(na.omit(gender)),
    .groups = "drop"
  )

## 3) Join residuals (row-level) to subject covariates (by pid)
df_res <- df_used %>% left_join(covs, by = "pid")

# Residuals by arm
ggplot(df_res, aes(x = arm, y = res)) +
  geom_boxplot() +
  theme_bw() +
  labs(title = "Residuals by arm", x = "Arm", y = "Normalized residuals")

# Residuals by region
ggplot(df_res, aes(x = region, y = res)) +
  geom_boxplot() +
  theme_bw() +
  labs(title = "Residuals by region", x = "Region", y = "Normalized residuals")

# Residuals by gender
ggplot(df_res, aes(x = gender, y = res)) +
  geom_boxplot() +
  theme_bw() +
  labs(title = "Residuals by gender", x = "Gender", y = "Normalized residuals")
```

No clear difference.

## Correlation structures

Would changing the correlation structure help?

```{r}
plot(ACF(m4_ML, maxLag =10), alpha = 0.05)
```



```{r}
## Fit candidates (ML) ---------------------------------------------
m_base <- m4_ML  # your current ML model (no correlation)

m_car1 <- update(
  m_base,
  correlation = corCAR1(form = ~ pday | pid)  # continuous-time AR(1)
)

m_ar1  <- update(
  m_base,
  correlation = corARMA(p = 1, q = 0, form = ~ 1 | pid)  # discrete-time AR(2)
)

m_ma1  <- update(
  m_base,
  correlation = corARMA(p = 0, q = 1, form = ~ 1 | pid)  # discrete-time MA(2)
)

m_arma11 <- update(
  m_base,
  correlation = corARMA(p = 1, q = 1, form = ~ 1 | pid)  # discrete-time ARMA(1,1)
)

m_ar2  <- update(
  m_base,
  correlation = corARMA(p = 2, q = 0, form = ~ 1 | pid)  # discrete-time AR(2)
)

m_ma2  <- update(
  m_base,
  correlation = corARMA(p = 0, q = 2, form = ~ 1 | pid)  # discrete-time MA(2)
)

m_arma21 <- update(
  m_base,
  correlation = corARMA(p = 2, q = 1, form = ~ 1 | pid)  # discrete-time ARMA(2,1)
)

m_arma12 <- update(
  m_base,
  correlation = corARMA(p = 1, q = 2, form = ~ 1 | pid)  # discrete-time ARMA(1,2)
)

## Compare by AIC (not all are nested) -----------------------------
AIC(m_base, m_car1, m_ar1, m_ma1, m_arma11,
    m_ar2, m_ma2, m_arma12, m_arma21)

## For nested pairs you can also do LRTs; e.g., base vs car1:
anova(m_base, m_car1)  # cAR does not improve model fit

## Check residual ACF again on the better models -------------------
par(mfrow=c(2,2))
plot(ACF(m_ar1,  maxLag = 10), alpha = 0.05, main = "AR(1)")
plot(ACF(m_arma11,  maxLag = 10), alpha = 0.05, main = "ARMA(1,1)")
plot(ACF(m_ar2,   maxLag = 10), alpha = 0.05, main = "AR(2)")
plot(ACF(m_arma21,   maxLag = 10), alpha = 0.05, main = "ARMA(2,1)")
par(mfrow=c(1,1))
# none of these get rid of the autocorrelations, pointing to some other missfit
```

## Final consideration: log transform Pyr

```{r}
# Add small offset
eps <- 1e-3
pyr_df_cc$logPyr <- log(pyr_df_cc$Pyrconcentration + eps)
hist(pyr_df_cc$logPyr)

pyr_gd_log <- groupedData(logPyr ~ pday | pid, data = pyr_df_cc)

pyr_nls_log <- nlsList(
  logPyr ~ SSfol(Dose_Pyr, pday, lKe, lKa, lCl),
  data      = pyr_gd_log,
  na.action = na.omit,
  control   = nls.control(maxiter = 100, warnOnly = TRUE)
)

# fit the base model:
m_log0_ML <- nlme(
  pyr_nls_log,
  random = lKe + lKa + lCl ~ 1,
  method  = "ML"
)
summary(m_log0_ML) 
VarCorr(m_log0_ML)
# random effects almost all zero, model likely overparameterized
# drop to only lKe:

m_log1_ML <- update(
  m_log0_ML,
  random = lKe ~ 1,
  method  = "ML"
)
summary(m_log1_ML)
# random effect still almost zero
# let's try adding covariates anyways

beta0 <- unname(fixef(m_log1_ML))  # starting values

m_log_cov_ML <- update(
  m_log1_ML,
  fixed = list(
    lKe ~ 1 + c_weight + I(c_weight^2) + c_age,
    lKa ~ 1,
    lCl ~ 1
  ),
  start = c(
    beta0[1], 0, 0, 0,  # lKe intercept + slopes
    beta0[2],           # lKa intercept
    beta0[3]            # lCl intercept
  )
)
summary(m_log_cov_ML)
anova(m_log1_ML, m_log_cov_ML)
# none of the covariates are significant!

# refit the basic model with REML
m_log_final <- update(m_log1_ML, method = "REML")
summary(m_log_final)
plot(m_log_final)

qqnorm(resid(m_log_final, type = "normalized")); qqline(resid(m_log_final, type = "normalized"))

hist(resid(m_log_final, type = "normalized"))

AIC(m4_ML, m_log_final)
```

## Compare raw scale and log scale

```{r}
## --- Choose which models to compare (ML fits) ---
m_raw <- m4_ML        # raw-scale ML model
m_log <- m_log1_ML    # log-scale ML model

## --- 1) AIC/BIC comparison table ---
cmp <- data.frame(
  model = c("Raw scale", "Log scale"),
  AIC   = c(AIC(m_raw), AIC(m_log)),
  BIC   = c(BIC(m_raw), BIC(m_log)),
  nobs  = c(nobs(m_raw), nobs(m_log))
)
cmp[order(cmp$AIC), ]   # lower is better
```

```{r}
## --- 2) Residual diagnostics side-by-side ---
par(mfrow = c(2,3), mar = c(4,4,2,1))

# RAW: residuals
res_raw <- resid(m_raw, type = "normalized")
fit_raw <- fitted(m_raw)
plot(fit_raw, res_raw, main = "Raw: Residuals vs Fitted",
     xlab = "Fitted", ylab = "Residuals"); abline(h=0, lty=2)
qqnorm(res_raw, main = "Raw: QQ plot"); qqline(res_raw, col="red", lwd=2)
hist(res_raw, breaks=20, prob=TRUE, main="Raw: Residuals hist", xlab="Residuals")
lines(density(res_raw), lwd=2, col="blue")

# LOG: residuals
res_log <- resid(m_log, type = "normalized")
fit_log <- fitted(m_log)
plot(fit_log, res_log, main = "Log: Residuals vs Fitted",
     xlab = "Fitted", ylab = "Residuals"); abline(h=0, lty=2)
qqnorm(res_log, main = "Log: QQ plot"); qqline(res_log, col="red", lwd=2)
hist(res_log, breaks=20, prob=TRUE, main="Log: Residuals hist", xlab="Residuals")
lines(density(res_log), lwd=2, col="blue")

par(mfrow = c(1,1))
```


```{r}
## --- 3) Residual autocorrelation (ACF) comparison ---
par(mfrow=c(1,2), mar=c(4,4,2,1))
plot(ACF(m_raw, maxLag=10), alpha=0.05, main="Raw: residual ACF")
plot(ACF(m_log, maxLag=10), alpha=0.05, main="Log: residual ACF")
par(mfrow=c(1,1))
```

On the log scale, the model achieved lower AIC/BIC, suggesting improved fit. However, residual diagnostics (QQ plot with a central step, bimodal residual histogram, and large autocorrelations at later time points) indicated model misspecification and failure to capture subject-level heterogeneity. In contrast, the raw-scale model had higher AIC/BIC but more interpretable residual distributions and non-negligible random effects. Given this trade-off, we conclude that while the log scale may improve global fit, the raw scale provides a more realistic description of individual-level variability.




